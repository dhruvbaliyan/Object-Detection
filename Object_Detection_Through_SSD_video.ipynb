{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "177l2ufTPP0IfJ0i_XRXn98DOBo0_zCQ2",
      "authorship_tag": "ABX9TyPjjQL/i6s2V9XWW1wSBfxe",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dhruvbaliyan/Object-Detection/blob/main/Object_Detection_Through_SSD_video.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Beginner Warning**\n",
        "This is dependent on a separate library which is not part of Tensorflow (but still made by the Tensorflow team).\n",
        "\n",
        "Some beginners got \"stuck\" in the past when Tensorflow 2 came out, but this library was not compatible with Tensorflow 2.\n",
        "\n",
        "Beginners often feel uncomfortable using older versions of libraries. This is not how things work in the real world.\n",
        "\n",
        "See \"Why bad programmers always need the latest version\": https://youtu.be/BIXH_m6CT2I\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "f_CcXjm3hGcq"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "VajgJehYg3xO",
        "outputId": "2fdeff5e-632b-4b0a-9664-4186ff0d2726"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: numpy==1.26.4 in /usr/local/lib/python3.12/dist-packages (1.26.4)\n",
            "Requirement already satisfied: tensorflow==2.19.0 in /usr/local/lib/python3.12/dist-packages (2.19.0)\n",
            "Requirement already satisfied: tf-models-official==2.19.1 in /usr/local/lib/python3.12/dist-packages (2.19.1)\n",
            "Requirement already satisfied: protobuf<=3.20.3 in /usr/local/lib/python3.12/dist-packages (3.20.3)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow==2.19.0) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow==2.19.0) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.12/dist-packages (from tensorflow==2.19.0) (25.9.23)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.12/dist-packages (from tensorflow==2.19.0) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.12/dist-packages (from tensorflow==2.19.0) (0.2.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow==2.19.0) (18.1.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.12/dist-packages (from tensorflow==2.19.0) (3.4.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from tensorflow==2.19.0) (25.0)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow==2.19.0) (2.32.4)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from tensorflow==2.19.0) (75.2.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow==2.19.0) (1.17.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow==2.19.0) (3.2.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.12/dist-packages (from tensorflow==2.19.0) (4.15.0)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow==2.19.0) (2.0.1)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.12/dist-packages (from tensorflow==2.19.0) (1.76.0)\n",
            "Requirement already satisfied: tensorboard~=2.19.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow==2.19.0) (2.19.0)\n",
            "Requirement already satisfied: keras>=3.5.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow==2.19.0) (3.10.0)\n",
            "Requirement already satisfied: h5py>=3.11.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow==2.19.0) (3.15.1)\n",
            "Requirement already satisfied: ml-dtypes<1.0.0,>=0.5.1 in /usr/local/lib/python3.12/dist-packages (from tensorflow==2.19.0) (0.5.4)\n",
            "Requirement already satisfied: google-api-python-client>=1.6.7 in /usr/local/lib/python3.12/dist-packages (from tf-models-official==2.19.1) (2.187.0)\n",
            "Requirement already satisfied: kaggle>=1.3.9 in /usr/local/lib/python3.12/dist-packages (from tf-models-official==2.19.1) (1.7.4.5)\n",
            "Requirement already satisfied: oauth2client in /usr/local/lib/python3.12/dist-packages (from tf-models-official==2.19.1) (4.1.3)\n",
            "Requirement already satisfied: pandas>=0.22.0 in /usr/local/lib/python3.12/dist-packages (from tf-models-official==2.19.1) (2.2.2)\n",
            "Requirement already satisfied: psutil>=5.4.3 in /usr/local/lib/python3.12/dist-packages (from tf-models-official==2.19.1) (5.9.5)\n",
            "Requirement already satisfied: py-cpuinfo>=3.3.0 in /usr/local/lib/python3.12/dist-packages (from tf-models-official==2.19.1) (9.0.0)\n",
            "Requirement already satisfied: scipy>=0.19.1 in /usr/local/lib/python3.12/dist-packages (from tf-models-official==2.19.1) (1.16.3)\n",
            "Requirement already satisfied: tensorflow-hub>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from tf-models-official==2.19.1) (0.16.1)\n",
            "Requirement already satisfied: tensorflow-model-optimization>=0.4.1 in /usr/local/lib/python3.12/dist-packages (from tf-models-official==2.19.1) (0.8.0)\n",
            "Requirement already satisfied: tensorflow-datasets in /usr/local/lib/python3.12/dist-packages (from tf-models-official==2.19.1) (4.9.9)\n",
            "Requirement already satisfied: tf-keras>=2.16.0 in /usr/local/lib/python3.12/dist-packages (from tf-models-official==2.19.1) (2.19.0)\n",
            "Requirement already satisfied: gin-config in /usr/local/lib/python3.12/dist-packages (from tf-models-official==2.19.1) (0.5.0)\n",
            "Requirement already satisfied: tf_slim>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from tf-models-official==2.19.1) (1.1.0)\n",
            "Requirement already satisfied: Cython in /usr/local/lib/python3.12/dist-packages (from tf-models-official==2.19.1) (3.0.12)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.12/dist-packages (from tf-models-official==2.19.1) (3.10.0)\n",
            "Requirement already satisfied: pyyaml>=6.0.0 in /usr/local/lib/python3.12/dist-packages (from tf-models-official==2.19.1) (6.0.3)\n",
            "Requirement already satisfied: opencv-python-headless in /usr/local/lib/python3.12/dist-packages (from tf-models-official==2.19.1) (4.11.0.86)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.12/dist-packages (from tf-models-official==2.19.1) (11.3.0)\n",
            "Requirement already satisfied: pycocotools in /usr/local/lib/python3.12/dist-packages (from tf-models-official==2.19.1) (2.0.10)\n",
            "Requirement already satisfied: seqeval in /usr/local/lib/python3.12/dist-packages (from tf-models-official==2.19.1) (1.2.2)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.12/dist-packages (from tf-models-official==2.19.1) (0.2.1)\n",
            "Requirement already satisfied: sacrebleu in /usr/local/lib/python3.12/dist-packages (from tf-models-official==2.19.1) (2.5.1)\n",
            "Requirement already satisfied: immutabledict in /usr/local/lib/python3.12/dist-packages (from tf-models-official==2.19.1) (4.2.2)\n",
            "Requirement already satisfied: ai-edge-litert>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from tf-models-official==2.19.1) (2.0.3)\n",
            "Requirement already satisfied: tensorflow-text~=2.19.0 in /usr/local/lib/python3.12/dist-packages (from tf-models-official==2.19.1) (2.19.0)\n",
            "Requirement already satisfied: backports.strenum in /usr/local/lib/python3.12/dist-packages (from ai-edge-litert>=1.0.1->tf-models-official==2.19.1) (1.2.8)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from ai-edge-litert>=1.0.1->tf-models-official==2.19.1) (4.67.1)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from astunparse>=1.6.0->tensorflow==2.19.0) (0.45.1)\n",
            "Requirement already satisfied: httplib2<1.0.0,>=0.19.0 in /usr/local/lib/python3.12/dist-packages (from google-api-python-client>=1.6.7->tf-models-official==2.19.1) (0.31.0)\n",
            "Requirement already satisfied: google-auth!=2.24.0,!=2.25.0,<3.0.0,>=1.32.0 in /usr/local/lib/python3.12/dist-packages (from google-api-python-client>=1.6.7->tf-models-official==2.19.1) (2.43.0)\n",
            "Requirement already satisfied: google-auth-httplib2<1.0.0,>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from google-api-python-client>=1.6.7->tf-models-official==2.19.1) (0.2.1)\n",
            "Requirement already satisfied: google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0,>=1.31.5 in /usr/local/lib/python3.12/dist-packages (from google-api-python-client>=1.6.7->tf-models-official==2.19.1) (2.28.1)\n",
            "Requirement already satisfied: uritemplate<5,>=3.0.1 in /usr/local/lib/python3.12/dist-packages (from google-api-python-client>=1.6.7->tf-models-official==2.19.1) (4.2.0)\n",
            "Requirement already satisfied: bleach in /usr/local/lib/python3.12/dist-packages (from kaggle>=1.3.9->tf-models-official==2.19.1) (6.3.0)\n",
            "Requirement already satisfied: certifi>=14.05.14 in /usr/local/lib/python3.12/dist-packages (from kaggle>=1.3.9->tf-models-official==2.19.1) (2025.11.12)\n",
            "Requirement already satisfied: charset-normalizer in /usr/local/lib/python3.12/dist-packages (from kaggle>=1.3.9->tf-models-official==2.19.1) (3.4.4)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.12/dist-packages (from kaggle>=1.3.9->tf-models-official==2.19.1) (3.11)\n",
            "Requirement already satisfied: python-dateutil>=2.5.3 in /usr/local/lib/python3.12/dist-packages (from kaggle>=1.3.9->tf-models-official==2.19.1) (2.9.0.post0)\n",
            "Requirement already satisfied: python-slugify in /usr/local/lib/python3.12/dist-packages (from kaggle>=1.3.9->tf-models-official==2.19.1) (8.0.4)\n",
            "Requirement already satisfied: text-unidecode in /usr/local/lib/python3.12/dist-packages (from kaggle>=1.3.9->tf-models-official==2.19.1) (1.3)\n",
            "Requirement already satisfied: urllib3>=1.15.1 in /usr/local/lib/python3.12/dist-packages (from kaggle>=1.3.9->tf-models-official==2.19.1) (2.5.0)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.12/dist-packages (from kaggle>=1.3.9->tf-models-official==2.19.1) (0.5.1)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.12/dist-packages (from keras>=3.5.0->tensorflow==2.19.0) (13.9.4)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.12/dist-packages (from keras>=3.5.0->tensorflow==2.19.0) (0.1.0)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.12/dist-packages (from keras>=3.5.0->tensorflow==2.19.0) (0.18.0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas>=0.22.0->tf-models-official==2.19.1) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas>=0.22.0->tf-models-official==2.19.1) (2025.2)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.12/dist-packages (from tensorboard~=2.19.0->tensorflow==2.19.0) (3.10)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.12/dist-packages (from tensorboard~=2.19.0->tensorflow==2.19.0) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from tensorboard~=2.19.0->tensorflow==2.19.0) (3.1.3)\n",
            "Requirement already satisfied: dm-tree~=0.1.1 in /usr/local/lib/python3.12/dist-packages (from tensorflow-model-optimization>=0.4.1->tf-models-official==2.19.1) (0.1.9)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->tf-models-official==2.19.1) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib->tf-models-official==2.19.1) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib->tf-models-official==2.19.1) (4.60.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->tf-models-official==2.19.1) (1.4.9)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->tf-models-official==2.19.1) (3.2.5)\n",
            "Requirement already satisfied: pyasn1>=0.1.7 in /usr/local/lib/python3.12/dist-packages (from oauth2client->tf-models-official==2.19.1) (0.6.1)\n",
            "Requirement already satisfied: pyasn1-modules>=0.0.5 in /usr/local/lib/python3.12/dist-packages (from oauth2client->tf-models-official==2.19.1) (0.4.2)\n",
            "Requirement already satisfied: rsa>=3.1.4 in /usr/local/lib/python3.12/dist-packages (from oauth2client->tf-models-official==2.19.1) (4.9.1)\n",
            "Requirement already satisfied: portalocker in /usr/local/lib/python3.12/dist-packages (from sacrebleu->tf-models-official==2.19.1) (3.2.0)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.12/dist-packages (from sacrebleu->tf-models-official==2.19.1) (2025.11.3)\n",
            "Requirement already satisfied: tabulate>=0.8.9 in /usr/local/lib/python3.12/dist-packages (from sacrebleu->tf-models-official==2.19.1) (0.9.0)\n",
            "Requirement already satisfied: colorama in /usr/local/lib/python3.12/dist-packages (from sacrebleu->tf-models-official==2.19.1) (0.4.6)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.12/dist-packages (from sacrebleu->tf-models-official==2.19.1) (6.0.2)\n",
            "Requirement already satisfied: scikit-learn>=0.21.3 in /usr/local/lib/python3.12/dist-packages (from seqeval->tf-models-official==2.19.1) (1.6.1)\n",
            "Requirement already satisfied: array_record>=0.5.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow-datasets->tf-models-official==2.19.1) (0.8.3)\n",
            "Requirement already satisfied: etils>=1.9.1 in /usr/local/lib/python3.12/dist-packages (from etils[edc,enp,epath,epy,etree]>=1.9.1; python_version >= \"3.11\"->tensorflow-datasets->tf-models-official==2.19.1) (1.13.0)\n",
            "Requirement already satisfied: promise in /usr/local/lib/python3.12/dist-packages (from tensorflow-datasets->tf-models-official==2.19.1) (2.3)\n",
            "Requirement already satisfied: pyarrow in /usr/local/lib/python3.12/dist-packages (from tensorflow-datasets->tf-models-official==2.19.1) (18.1.0)\n",
            "Requirement already satisfied: simple_parsing in /usr/local/lib/python3.12/dist-packages (from tensorflow-datasets->tf-models-official==2.19.1) (0.1.7)\n",
            "Requirement already satisfied: tensorflow-metadata in /usr/local/lib/python3.12/dist-packages (from tensorflow-datasets->tf-models-official==2.19.1) (1.14.0)\n",
            "Requirement already satisfied: toml in /usr/local/lib/python3.12/dist-packages (from tensorflow-datasets->tf-models-official==2.19.1) (0.10.2)\n",
            "Requirement already satisfied: attrs>=18.2.0 in /usr/local/lib/python3.12/dist-packages (from dm-tree~=0.1.1->tensorflow-model-optimization>=0.4.1->tf-models-official==2.19.1) (25.4.0)\n",
            "Requirement already satisfied: einops in /usr/local/lib/python3.12/dist-packages (from etils[edc,enp,epath,epy,etree]>=1.9.1; python_version >= \"3.11\"->tensorflow-datasets->tf-models-official==2.19.1) (0.8.1)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from etils[edc,enp,epath,epy,etree]>=1.9.1; python_version >= \"3.11\"->tensorflow-datasets->tf-models-official==2.19.1) (2025.3.0)\n",
            "Requirement already satisfied: importlib_resources in /usr/local/lib/python3.12/dist-packages (from etils[edc,enp,epath,epy,etree]>=1.9.1; python_version >= \"3.11\"->tensorflow-datasets->tf-models-official==2.19.1) (6.5.2)\n",
            "Requirement already satisfied: zipp in /usr/local/lib/python3.12/dist-packages (from etils[edc,enp,epath,epy,etree]>=1.9.1; python_version >= \"3.11\"->tensorflow-datasets->tf-models-official==2.19.1) (3.23.0)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0.0,>=1.56.2 in /usr/local/lib/python3.12/dist-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0,>=1.31.5->google-api-python-client>=1.6.7->tf-models-official==2.19.1) (1.72.0)\n",
            "Requirement already satisfied: proto-plus<2.0.0,>=1.22.3 in /usr/local/lib/python3.12/dist-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0,>=1.31.5->google-api-python-client>=1.6.7->tf-models-official==2.19.1) (1.26.1)\n",
            "Requirement already satisfied: cachetools<7.0,>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0,>=1.32.0->google-api-python-client>=1.6.7->tf-models-official==2.19.1) (6.2.2)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn>=0.21.3->seqeval->tf-models-official==2.19.1) (1.5.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn>=0.21.3->seqeval->tf-models-official==2.19.1) (3.6.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.12/dist-packages (from werkzeug>=1.0.1->tensorboard~=2.19.0->tensorflow==2.19.0) (3.0.3)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from rich->keras>=3.5.0->tensorflow==2.19.0) (4.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.12/dist-packages (from rich->keras>=3.5.0->tensorflow==2.19.0) (2.19.2)\n",
            "Requirement already satisfied: docstring-parser<1.0,>=0.15 in /usr/local/lib/python3.12/dist-packages (from simple_parsing->tensorflow-datasets->tf-models-official==2.19.1) (0.17.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.12/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow==2.19.0) (0.1.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install -U \"numpy==1.26.4\" \"tensorflow==2.19.0\" \"tf-models-official==2.19.1\" \"protobuf<=3.20.3\""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/tensorflow/models.git\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_CMduJlai-da",
        "outputId": "519768a2-6a0a-440e-ff78-a45857bc2c21"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'models'...\n",
            "remote: Enumerating objects: 102910, done.\u001b[K\n",
            "remote: Counting objects: 100% (223/223), done.\u001b[K\n",
            "remote: Compressing objects: 100% (130/130), done.\u001b[K\n",
            "remote: Total 102910 (delta 164), reused 101 (delta 93), pack-reused 102687 (from 3)\u001b[K\n",
            "Receiving objects: 100% (102910/102910), 642.87 MiB | 20.87 MiB/s, done.\n",
            "Resolving deltas: 100% (74333/74333), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/models/research"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0BOGe4Y1jHL_",
        "outputId": "f52f02a0-52a2-41cc-b19f-f28b69cdacac"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/models/research\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "30ACT8xRjYRs",
        "outputId": "cbaf73f8-d531-46bb-ed05-be1fdcd97f4c"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "adversarial_text    deeplab\t\t   marco\t     seq_flow_lite\n",
            "attention_ocr\t    deep_speech\t\t   nst_blogpost      slim\n",
            "audioset\t    delf\t\t   object_detection  vid2depth\n",
            "autoaugment\t    efficient-hrl\t   pcl_rl\n",
            "cognitive_planning  lfads\t\t   README.md\n",
            "cvt_text\t    lstm_object_detection  rebar\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### **TensorFlow** **Model** **Garden**\n",
        "\n",
        "A big collection of implemented\n",
        "\n",
        "*   ML models (vision, NLP, detection, etc.) built with TensorFlow.\n",
        "\n",
        "*   Contains reference implementations of SOTA papers, plus training scripts, configs, and example datasets.\n",
        "\n",
        "*   Meant to show best practices and give you ready-to-run code you can fine-tune on your own data.\n",
        "\n",
        "\n",
        "\n",
        "`Ready-made AI models you can use right away`\n",
        "\n",
        "**SOTA- State Of The Art**\n",
        "\n",
        "✔ It is the best-performing model currently known\n",
        "\n",
        "✔ On a specific task\n",
        "\n",
        "✔ Compared using a benchmark or public dataset\n",
        "\n"
      ],
      "metadata": {
        "id": "NKjxF6xRjULv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "####**Install Protobuf**\n",
        "\n",
        "No need to do this if you are on Colab.\n",
        "\n",
        "If you're doing this locally, download the latest Protobuf library for your OS from https://github.com/google/protobuf/releases\n",
        "\n",
        "The filename should look like \"protoc-*-*.zip\".\n",
        "\n",
        "Example: protoc-3.17.3-win64.zip if you are using 64-bit Windows.\n",
        "\n",
        "Assuming you've unzipped this zip file to \\<path>, the next step is to add \\<path>/bin to your PATH environment variable (on Linux or Mac).\n",
        "\n",
        "Once Protobuf has been successfully installed, you can run the following command (note: must be done from the models/research folder)."
      ],
      "metadata": {
        "id": "Bo8v-jS-hI2g"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!apt-get install -y protobuf-compiler"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "azxlbj6njgMy",
        "outputId": "a42dbf99-4975-41da-c7de-8ba1779a7f48"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "protobuf-compiler is already the newest version (3.12.4-1ubuntu7.22.04.4).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 41 not upgraded.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!protoc object_detection/protos/*.proto --python_out=."
      ],
      "metadata": {
        "id": "8aLMcm9ZjmUd"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "| Part                              | Meaning                                                              |\n",
        "| --------------------------------- | -------------------------------------------------------------------- |\n",
        "| `!`                               | \"Run a shell command\" (used in Jupyter Notebook / Colab)             |\n",
        "| `cd models/research/`             | Move into the `research` folder where the Object Detection API lives |\n",
        "| `&&`                              | Run the next command only if cd worked                               |\n",
        "| `protoc`                          | Protobuf compiler tool                                               |\n",
        "| `object_detection/protos/*.proto` | Compile **all** .proto files inside the `protos` folder              |\n",
        "| `--python_out=.`                  | Output the generated Python files **into the same folder**           |\n"
      ],
      "metadata": {
        "id": "TFqrv1vGhS1D"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Install the object detection API**"
      ],
      "metadata": {
        "id": "h98W1_d1hiHc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!cp object_detection/packages/tf2/setup.py .\n",
        "!python -m pip install ."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "EFMQFfCojr5t",
        "outputId": "cc410f98-0d74-4faa-efbb-aa1d1e962253"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing /content/models/research\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting avro-python3 (from object_detection==0.1)\n",
            "  Downloading avro-python3-1.10.2.tar.gz (38 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting apache-beam (from object_detection==0.1)\n",
            "  Downloading apache_beam-2.69.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (21 kB)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.12/dist-packages (from object_detection==0.1) (11.3.0)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.12/dist-packages (from object_detection==0.1) (6.0.2)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.12/dist-packages (from object_detection==0.1) (3.10.0)\n",
            "Requirement already satisfied: Cython in /usr/local/lib/python3.12/dist-packages (from object_detection==0.1) (3.0.12)\n",
            "Collecting contextlib2 (from object_detection==0.1)\n",
            "  Downloading contextlib2-21.6.0-py2.py3-none-any.whl.metadata (4.1 kB)\n",
            "Requirement already satisfied: tf-slim in /usr/local/lib/python3.12/dist-packages (from object_detection==0.1) (1.1.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.12/dist-packages (from object_detection==0.1) (1.17.0)\n",
            "Requirement already satisfied: pycocotools in /usr/local/lib/python3.12/dist-packages (from object_detection==0.1) (2.0.10)\n",
            "Collecting lvis (from object_detection==0.1)\n",
            "  Downloading lvis-0.5.3-py3-none-any.whl.metadata (856 bytes)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.12/dist-packages (from object_detection==0.1) (1.16.3)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (from object_detection==0.1) (2.2.2)\n",
            "Requirement already satisfied: tf-models-official>=2.5.1 in /usr/local/lib/python3.12/dist-packages (from object_detection==0.1) (2.19.1)\n",
            "Collecting tensorflow_io (from object_detection==0.1)\n",
            "  Downloading tensorflow_io-0.37.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (14 kB)\n",
            "Requirement already satisfied: keras in /usr/local/lib/python3.12/dist-packages (from object_detection==0.1) (3.10.0)\n",
            "Collecting pyparsing==2.4.7 (from object_detection==0.1)\n",
            "  Downloading pyparsing-2.4.7-py2.py3-none-any.whl.metadata (3.6 kB)\n",
            "Collecting sacrebleu<=2.2.0 (from object_detection==0.1)\n",
            "  Downloading sacrebleu-2.2.0-py3-none-any.whl.metadata (55 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m55.4/55.4 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: portalocker in /usr/local/lib/python3.12/dist-packages (from sacrebleu<=2.2.0->object_detection==0.1) (3.2.0)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.12/dist-packages (from sacrebleu<=2.2.0->object_detection==0.1) (2025.11.3)\n",
            "Requirement already satisfied: tabulate>=0.8.9 in /usr/local/lib/python3.12/dist-packages (from sacrebleu<=2.2.0->object_detection==0.1) (0.9.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.12/dist-packages (from sacrebleu<=2.2.0->object_detection==0.1) (1.26.4)\n",
            "Requirement already satisfied: colorama in /usr/local/lib/python3.12/dist-packages (from sacrebleu<=2.2.0->object_detection==0.1) (0.4.6)\n",
            "Requirement already satisfied: google-api-python-client>=1.6.7 in /usr/local/lib/python3.12/dist-packages (from tf-models-official>=2.5.1->object_detection==0.1) (2.187.0)\n",
            "Requirement already satisfied: kaggle>=1.3.9 in /usr/local/lib/python3.12/dist-packages (from tf-models-official>=2.5.1->object_detection==0.1) (1.7.4.5)\n",
            "Requirement already satisfied: oauth2client in /usr/local/lib/python3.12/dist-packages (from tf-models-official>=2.5.1->object_detection==0.1) (4.1.3)\n",
            "Requirement already satisfied: psutil>=5.4.3 in /usr/local/lib/python3.12/dist-packages (from tf-models-official>=2.5.1->object_detection==0.1) (5.9.5)\n",
            "Requirement already satisfied: py-cpuinfo>=3.3.0 in /usr/local/lib/python3.12/dist-packages (from tf-models-official>=2.5.1->object_detection==0.1) (9.0.0)\n",
            "Requirement already satisfied: tensorflow-hub>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from tf-models-official>=2.5.1->object_detection==0.1) (0.16.1)\n",
            "Requirement already satisfied: tensorflow-model-optimization>=0.4.1 in /usr/local/lib/python3.12/dist-packages (from tf-models-official>=2.5.1->object_detection==0.1) (0.8.0)\n",
            "Requirement already satisfied: tensorflow-datasets in /usr/local/lib/python3.12/dist-packages (from tf-models-official>=2.5.1->object_detection==0.1) (4.9.9)\n",
            "Requirement already satisfied: tf-keras>=2.16.0 in /usr/local/lib/python3.12/dist-packages (from tf-models-official>=2.5.1->object_detection==0.1) (2.19.0)\n",
            "Requirement already satisfied: gin-config in /usr/local/lib/python3.12/dist-packages (from tf-models-official>=2.5.1->object_detection==0.1) (0.5.0)\n",
            "Requirement already satisfied: pyyaml>=6.0.0 in /usr/local/lib/python3.12/dist-packages (from tf-models-official>=2.5.1->object_detection==0.1) (6.0.3)\n",
            "Requirement already satisfied: opencv-python-headless in /usr/local/lib/python3.12/dist-packages (from tf-models-official>=2.5.1->object_detection==0.1) (4.11.0.86)\n",
            "Requirement already satisfied: seqeval in /usr/local/lib/python3.12/dist-packages (from tf-models-official>=2.5.1->object_detection==0.1) (1.2.2)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.12/dist-packages (from tf-models-official>=2.5.1->object_detection==0.1) (0.2.1)\n",
            "Requirement already satisfied: immutabledict in /usr/local/lib/python3.12/dist-packages (from tf-models-official>=2.5.1->object_detection==0.1) (4.2.2)\n",
            "Requirement already satisfied: ai-edge-litert>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from tf-models-official>=2.5.1->object_detection==0.1) (2.0.3)\n",
            "Requirement already satisfied: tensorflow~=2.19.0 in /usr/local/lib/python3.12/dist-packages (from tf-models-official>=2.5.1->object_detection==0.1) (2.19.0)\n",
            "Requirement already satisfied: tensorflow-text~=2.19.0 in /usr/local/lib/python3.12/dist-packages (from tf-models-official>=2.5.1->object_detection==0.1) (2.19.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas->object_detection==0.1) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas->object_detection==0.1) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas->object_detection==0.1) (2025.2)\n",
            "Requirement already satisfied: absl-py>=0.2.2 in /usr/local/lib/python3.12/dist-packages (from tf-slim->object_detection==0.1) (1.4.0)\n",
            "Collecting crcmod<2.0,>=1.7 (from apache-beam->object_detection==0.1)\n",
            "  Downloading crcmod-1.7.tar.gz (89 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m89.7/89.7 kB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: cryptography<48.0.0,>=39.0.0 in /usr/local/lib/python3.12/dist-packages (from apache-beam->object_detection==0.1) (43.0.3)\n",
            "Requirement already satisfied: orjson<4,>=3.9.7 in /usr/local/lib/python3.12/dist-packages (from apache-beam->object_detection==0.1) (3.11.4)\n",
            "Collecting fastavro<2,>=0.23.6 (from apache-beam->object_detection==0.1)\n",
            "  Downloading fastavro-1.12.1-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (5.8 kB)\n",
            "Collecting fasteners<1.0,>=0.3 (from apache-beam->object_detection==0.1)\n",
            "  Downloading fasteners-0.20-py3-none-any.whl.metadata (4.8 kB)\n",
            "Collecting grpcio!=1.48.0,!=1.59.*,!=1.60.*,!=1.61.*,!=1.62.0,!=1.62.1,<1.66.0,<2,>=1.33.1 (from apache-beam->object_detection==0.1)\n",
            "  Downloading grpcio-1.65.5-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.3 kB)\n",
            "Collecting hdfs<3.0.0,>=2.1.0 (from apache-beam->object_detection==0.1)\n",
            "  Downloading hdfs-2.7.3.tar.gz (43 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.5/43.5 kB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting httplib2<0.23.0,>=0.8 (from apache-beam->object_detection==0.1)\n",
            "  Downloading httplib2-0.22.0-py3-none-any.whl.metadata (2.6 kB)\n",
            "Requirement already satisfied: jsonschema<5.0.0,>=4.0.0 in /usr/local/lib/python3.12/dist-packages (from apache-beam->object_detection==0.1) (4.25.1)\n",
            "Collecting jsonpickle<4.0.0,>=3.0.0 (from apache-beam->object_detection==0.1)\n",
            "  Downloading jsonpickle-3.4.2-py3-none-any.whl.metadata (8.1 kB)\n",
            "Collecting objsize<0.8.0,>=0.6.1 (from apache-beam->object_detection==0.1)\n",
            "  Downloading objsize-0.7.1-py3-none-any.whl.metadata (12 kB)\n",
            "Requirement already satisfied: packaging>=22.0 in /usr/local/lib/python3.12/dist-packages (from apache-beam->object_detection==0.1) (25.0)\n",
            "Collecting pymongo<5.0.0,>=3.8.0 (from apache-beam->object_detection==0.1)\n",
            "  Downloading pymongo-4.15.5-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (22 kB)\n",
            "Requirement already satisfied: proto-plus<2,>=1.7.1 in /usr/local/lib/python3.12/dist-packages (from apache-beam->object_detection==0.1) (1.26.1)\n",
            "Requirement already satisfied: protobuf!=4.0.*,!=4.21.*,!=4.22.0,!=4.23.*,!=4.24.*,<7.0.0.dev0,>=3.20.3 in /usr/local/lib/python3.12/dist-packages (from apache-beam->object_detection==0.1) (3.20.3)\n",
            "Collecting pydot<2,>=1.2.0 (from apache-beam->object_detection==0.1)\n",
            "  Downloading pydot-1.4.2-py2.py3-none-any.whl.metadata (8.0 kB)\n",
            "Collecting redis<6,>=5.0.0 (from apache-beam->object_detection==0.1)\n",
            "  Downloading redis-5.3.1-py3-none-any.whl.metadata (9.2 kB)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.32.4 in /usr/local/lib/python3.12/dist-packages (from apache-beam->object_detection==0.1) (2.32.4)\n",
            "Requirement already satisfied: sortedcontainers>=2.4.0 in /usr/local/lib/python3.12/dist-packages (from apache-beam->object_detection==0.1) (2.4.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.0 in /usr/local/lib/python3.12/dist-packages (from apache-beam->object_detection==0.1) (4.15.0)\n",
            "Requirement already satisfied: zstandard<1,>=0.18.0 in /usr/local/lib/python3.12/dist-packages (from apache-beam->object_detection==0.1) (0.25.0)\n",
            "Collecting beartype<0.22.0,>=0.21.0 (from apache-beam->object_detection==0.1)\n",
            "  Downloading beartype-0.21.0-py3-none-any.whl.metadata (33 kB)\n",
            "Requirement already satisfied: pyarrow<19.0.0,>=3.0.0 in /usr/local/lib/python3.12/dist-packages (from apache-beam->object_detection==0.1) (18.1.0)\n",
            "Collecting pyarrow-hotfix<1 (from apache-beam->object_detection==0.1)\n",
            "  Downloading pyarrow_hotfix-0.7-py3-none-any.whl.metadata (3.6 kB)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.12/dist-packages (from keras->object_detection==0.1) (13.9.4)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.12/dist-packages (from keras->object_detection==0.1) (0.1.0)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.12/dist-packages (from keras->object_detection==0.1) (3.15.1)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.12/dist-packages (from keras->object_detection==0.1) (0.18.0)\n",
            "Requirement already satisfied: ml-dtypes in /usr/local/lib/python3.12/dist-packages (from keras->object_detection==0.1) (0.5.4)\n",
            "Requirement already satisfied: cycler>=0.10.0 in /usr/local/lib/python3.12/dist-packages (from lvis->object_detection==0.1) (0.12.1)\n",
            "Requirement already satisfied: kiwisolver>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from lvis->object_detection==0.1) (1.4.9)\n",
            "Requirement already satisfied: opencv-python>=4.1.0.25 in /usr/local/lib/python3.12/dist-packages (from lvis->object_detection==0.1) (4.12.0.88)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->object_detection==0.1) (1.3.3)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib->object_detection==0.1) (4.60.1)\n",
            "Collecting tensorflow-io-gcs-filesystem==0.37.1 (from tensorflow_io->object_detection==0.1)\n",
            "  Downloading tensorflow_io_gcs_filesystem-0.37.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (14 kB)\n",
            "Requirement already satisfied: backports.strenum in /usr/local/lib/python3.12/dist-packages (from ai-edge-litert>=1.0.1->tf-models-official>=2.5.1->object_detection==0.1) (1.2.8)\n",
            "Requirement already satisfied: flatbuffers in /usr/local/lib/python3.12/dist-packages (from ai-edge-litert>=1.0.1->tf-models-official>=2.5.1->object_detection==0.1) (25.9.23)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from ai-edge-litert>=1.0.1->tf-models-official>=2.5.1->object_detection==0.1) (4.67.1)\n",
            "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.12/dist-packages (from cryptography<48.0.0,>=39.0.0->apache-beam->object_detection==0.1) (2.0.0)\n",
            "Requirement already satisfied: google-auth!=2.24.0,!=2.25.0,<3.0.0,>=1.32.0 in /usr/local/lib/python3.12/dist-packages (from google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object_detection==0.1) (2.43.0)\n",
            "Requirement already satisfied: google-auth-httplib2<1.0.0,>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object_detection==0.1) (0.2.1)\n",
            "Requirement already satisfied: google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0,>=1.31.5 in /usr/local/lib/python3.12/dist-packages (from google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object_detection==0.1) (2.28.1)\n",
            "Requirement already satisfied: uritemplate<5,>=3.0.1 in /usr/local/lib/python3.12/dist-packages (from google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object_detection==0.1) (4.2.0)\n",
            "Collecting docopt (from hdfs<3.0.0,>=2.1.0->apache-beam->object_detection==0.1)\n",
            "  Downloading docopt-0.6.2.tar.gz (25 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.12/dist-packages (from jsonschema<5.0.0,>=4.0.0->apache-beam->object_detection==0.1) (25.4.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.12/dist-packages (from jsonschema<5.0.0,>=4.0.0->apache-beam->object_detection==0.1) (2025.9.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.12/dist-packages (from jsonschema<5.0.0,>=4.0.0->apache-beam->object_detection==0.1) (0.37.0)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.12/dist-packages (from jsonschema<5.0.0,>=4.0.0->apache-beam->object_detection==0.1) (0.29.0)\n",
            "Requirement already satisfied: bleach in /usr/local/lib/python3.12/dist-packages (from kaggle>=1.3.9->tf-models-official>=2.5.1->object_detection==0.1) (6.3.0)\n",
            "Requirement already satisfied: certifi>=14.05.14 in /usr/local/lib/python3.12/dist-packages (from kaggle>=1.3.9->tf-models-official>=2.5.1->object_detection==0.1) (2025.11.12)\n",
            "Requirement already satisfied: charset-normalizer in /usr/local/lib/python3.12/dist-packages (from kaggle>=1.3.9->tf-models-official>=2.5.1->object_detection==0.1) (3.4.4)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.12/dist-packages (from kaggle>=1.3.9->tf-models-official>=2.5.1->object_detection==0.1) (3.11)\n",
            "Requirement already satisfied: python-slugify in /usr/local/lib/python3.12/dist-packages (from kaggle>=1.3.9->tf-models-official>=2.5.1->object_detection==0.1) (8.0.4)\n",
            "Requirement already satisfied: setuptools>=21.0.0 in /usr/local/lib/python3.12/dist-packages (from kaggle>=1.3.9->tf-models-official>=2.5.1->object_detection==0.1) (75.2.0)\n",
            "Requirement already satisfied: text-unidecode in /usr/local/lib/python3.12/dist-packages (from kaggle>=1.3.9->tf-models-official>=2.5.1->object_detection==0.1) (1.3)\n",
            "Requirement already satisfied: urllib3>=1.15.1 in /usr/local/lib/python3.12/dist-packages (from kaggle>=1.3.9->tf-models-official>=2.5.1->object_detection==0.1) (2.5.0)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.12/dist-packages (from kaggle>=1.3.9->tf-models-official>=2.5.1->object_detection==0.1) (0.5.1)\n",
            "Collecting numpy>=1.17 (from sacrebleu<=2.2.0->object_detection==0.1)\n",
            "  Downloading numpy-2.2.6-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (62 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.0/62.0 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting dnspython<3.0.0,>=1.16.0 (from pymongo<5.0.0,>=3.8.0->apache-beam->object_detection==0.1)\n",
            "  Downloading dnspython-2.8.0-py3-none-any.whl.metadata (5.7 kB)\n",
            "Requirement already satisfied: PyJWT>=2.9.0 in /usr/local/lib/python3.12/dist-packages (from redis<6,>=5.0.0->apache-beam->object_detection==0.1) (2.10.1)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow~=2.19.0->tf-models-official>=2.5.1->object_detection==0.1) (1.6.3)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.12/dist-packages (from tensorflow~=2.19.0->tf-models-official>=2.5.1->object_detection==0.1) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.12/dist-packages (from tensorflow~=2.19.0->tf-models-official>=2.5.1->object_detection==0.1) (0.2.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow~=2.19.0->tf-models-official>=2.5.1->object_detection==0.1) (18.1.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.12/dist-packages (from tensorflow~=2.19.0->tf-models-official>=2.5.1->object_detection==0.1) (3.4.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow~=2.19.0->tf-models-official>=2.5.1->object_detection==0.1) (3.2.0)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow~=2.19.0->tf-models-official>=2.5.1->object_detection==0.1) (2.0.1)\n",
            "Requirement already satisfied: tensorboard~=2.19.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow~=2.19.0->tf-models-official>=2.5.1->object_detection==0.1) (2.19.0)\n",
            "Collecting numpy>=1.17 (from sacrebleu<=2.2.0->object_detection==0.1)\n",
            "  Downloading numpy-2.1.3-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (62 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.0/62.0 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: dm-tree~=0.1.1 in /usr/local/lib/python3.12/dist-packages (from tensorflow-model-optimization>=0.4.1->tf-models-official>=2.5.1->object_detection==0.1) (0.1.9)\n",
            "INFO: pip is looking at multiple versions of tensorflow-model-optimization to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting tensorflow-model-optimization>=0.4.1 (from tf-models-official>=2.5.1->object_detection==0.1)\n",
            "  Downloading tensorflow_model_optimization-0.7.5-py2.py3-none-any.whl.metadata (914 bytes)\n",
            "  Downloading tensorflow_model_optimization-0.7.4-py2.py3-none-any.whl.metadata (914 bytes)\n",
            "  Downloading tensorflow_model_optimization-0.7.3-py2.py3-none-any.whl.metadata (910 bytes)\n",
            "  Downloading tensorflow_model_optimization-0.7.2-py2.py3-none-any.whl.metadata (910 bytes)\n",
            "  Downloading tensorflow_model_optimization-0.7.1-py2.py3-none-any.whl.metadata (910 bytes)\n",
            "  Downloading tensorflow_model_optimization-0.7.0-py2.py3-none-any.whl.metadata (910 bytes)\n",
            "  Downloading tensorflow_model_optimization-0.6.0-py2.py3-none-any.whl.metadata (911 bytes)\n",
            "INFO: pip is still looking at multiple versions of tensorflow-model-optimization to determine which version is compatible with other requirements. This could take a while.\n",
            "  Downloading tensorflow_model_optimization-0.5.0-py2.py3-none-any.whl.metadata (911 bytes)\n",
            "  Downloading tensorflow_model_optimization-0.4.1-py2.py3-none-any.whl.metadata (911 bytes)\n",
            "Collecting tensorflow-hub>=0.6.0 (from tf-models-official>=2.5.1->object_detection==0.1)\n",
            "  Downloading tensorflow_hub-0.16.1-py2.py3-none-any.whl.metadata (1.3 kB)\n",
            "INFO: This is taking longer than usual. You might need to provide the dependency resolver with stricter constraints to reduce runtime. See https://pip.pypa.io/warnings/backtracking for guidance. If you want to abort this run, press Ctrl + C.\n",
            "  Downloading tensorflow_hub-0.16.0-py2.py3-none-any.whl.metadata (1.3 kB)\n",
            "  Downloading tensorflow_hub-0.15.0-py2.py3-none-any.whl.metadata (1.3 kB)\n",
            "  Downloading tensorflow_hub-0.14.0-py2.py3-none-any.whl.metadata (1.4 kB)\n",
            "  Downloading tensorflow_hub-0.13.0-py2.py3-none-any.whl.metadata (1.7 kB)\n",
            "  Downloading tensorflow_hub-0.12.0-py2.py3-none-any.whl.metadata (1.7 kB)\n",
            "  Downloading tensorflow_hub-0.11.0-py2.py3-none-any.whl.metadata (1.7 kB)\n",
            "  Downloading tensorflow_hub-0.10.0-py2.py3-none-any.whl.metadata (1.7 kB)\n",
            "  Downloading tensorflow_hub-0.9.0-py2.py3-none-any.whl.metadata (1.7 kB)\n",
            "  Downloading tensorflow_hub-0.8.0-py2.py3-none-any.whl.metadata (1.7 kB)\n",
            "  Downloading tensorflow_hub-0.7.0-py2.py3-none-any.whl.metadata (1.5 kB)\n",
            "  Downloading tensorflow_hub-0.6.0-py2.py3-none-any.whl.metadata (1.5 kB)\n",
            "Collecting ml-dtypes (from keras->object_detection==0.1)\n",
            "  Downloading ml_dtypes-0.5.4-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (8.9 kB)\n",
            "  Downloading ml_dtypes-0.5.3-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (8.9 kB)\n",
            "  Downloading ml_dtypes-0.5.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (21 kB)\n",
            "Collecting h5py (from keras->object_detection==0.1)\n",
            "  Downloading h5py-3.15.1-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (3.0 kB)\n",
            "  Downloading h5py-3.15.0-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (3.0 kB)\n",
            "  Downloading h5py-3.14.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.7 kB)\n",
            "  Downloading h5py-3.13.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.5 kB)\n",
            "  Downloading h5py-3.12.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.5 kB)\n",
            "  Downloading h5py-3.11.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.5 kB)\n",
            "Collecting tensorflow~=2.19.0 (from tf-models-official>=2.5.1->object_detection==0.1)\n",
            "  Downloading tensorflow-2.19.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.1 kB)\n",
            "  Downloading tensorflow-2.19.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.1 kB)\n",
            "Collecting opencv-python>=4.1.0.25 (from lvis->object_detection==0.1)\n",
            "  Downloading opencv_python-4.12.0.88-cp37-abi3-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (19 kB)\n",
            "\u001b[33m  WARNING: Retrying (Retry(total=4, connect=None, read=None, redirect=None, status=None)) after connection broken by 'ProtocolError('Connection aborted.', RemoteDisconnected('Remote end closed connection without response'))': /packages/2c/8b/90eb44a40476fa0e71e05a0283947cfd74a5d36121a11d926ad6f3193cc4/opencv_python-4.11.0.86-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata\u001b[0m\u001b[33m\n",
            "\u001b[0m  Downloading opencv_python-4.11.0.86-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (20 kB)\n",
            "Requirement already satisfied: pyasn1>=0.1.7 in /usr/local/lib/python3.12/dist-packages (from oauth2client->tf-models-official>=2.5.1->object_detection==0.1) (0.6.1)\n",
            "Requirement already satisfied: pyasn1-modules>=0.0.5 in /usr/local/lib/python3.12/dist-packages (from oauth2client->tf-models-official>=2.5.1->object_detection==0.1) (0.4.2)\n",
            "Requirement already satisfied: rsa>=3.1.4 in /usr/local/lib/python3.12/dist-packages (from oauth2client->tf-models-official>=2.5.1->object_detection==0.1) (4.9.1)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from rich->keras->object_detection==0.1) (4.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.12/dist-packages (from rich->keras->object_detection==0.1) (2.19.2)\n",
            "Requirement already satisfied: scikit-learn>=0.21.3 in /usr/local/lib/python3.12/dist-packages (from seqeval->tf-models-official>=2.5.1->object_detection==0.1) (1.6.1)\n",
            "Requirement already satisfied: array_record>=0.5.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow-datasets->tf-models-official>=2.5.1->object_detection==0.1) (0.8.3)\n",
            "Requirement already satisfied: etils>=1.9.1 in /usr/local/lib/python3.12/dist-packages (from etils[edc,enp,epath,epy,etree]>=1.9.1; python_version >= \"3.11\"->tensorflow-datasets->tf-models-official>=2.5.1->object_detection==0.1) (1.13.0)\n",
            "Requirement already satisfied: promise in /usr/local/lib/python3.12/dist-packages (from tensorflow-datasets->tf-models-official>=2.5.1->object_detection==0.1) (2.3)\n",
            "Requirement already satisfied: simple_parsing in /usr/local/lib/python3.12/dist-packages (from tensorflow-datasets->tf-models-official>=2.5.1->object_detection==0.1) (0.1.7)\n",
            "Requirement already satisfied: tensorflow-metadata in /usr/local/lib/python3.12/dist-packages (from tensorflow-datasets->tf-models-official>=2.5.1->object_detection==0.1) (1.14.0)\n",
            "Requirement already satisfied: toml in /usr/local/lib/python3.12/dist-packages (from tensorflow-datasets->tf-models-official>=2.5.1->object_detection==0.1) (0.10.2)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from astunparse>=1.6.0->tensorflow~=2.19.0->tf-models-official>=2.5.1->object_detection==0.1) (0.45.1)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.12/dist-packages (from cffi>=1.12->cryptography<48.0.0,>=39.0.0->apache-beam->object_detection==0.1) (2.23)\n",
            "Requirement already satisfied: einops in /usr/local/lib/python3.12/dist-packages (from etils[edc,enp,epath,epy,etree]>=1.9.1; python_version >= \"3.11\"->tensorflow-datasets->tf-models-official>=2.5.1->object_detection==0.1) (0.8.1)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from etils[edc,enp,epath,epy,etree]>=1.9.1; python_version >= \"3.11\"->tensorflow-datasets->tf-models-official>=2.5.1->object_detection==0.1) (2025.3.0)\n",
            "Requirement already satisfied: importlib_resources in /usr/local/lib/python3.12/dist-packages (from etils[edc,enp,epath,epy,etree]>=1.9.1; python_version >= \"3.11\"->tensorflow-datasets->tf-models-official>=2.5.1->object_detection==0.1) (6.5.2)\n",
            "Requirement already satisfied: zipp in /usr/local/lib/python3.12/dist-packages (from etils[edc,enp,epath,epy,etree]>=1.9.1; python_version >= \"3.11\"->tensorflow-datasets->tf-models-official>=2.5.1->object_detection==0.1) (3.23.0)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0.0,>=1.56.2 in /usr/local/lib/python3.12/dist-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0,>=1.31.5->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object_detection==0.1) (1.72.0)\n",
            "Requirement already satisfied: cachetools<7.0,>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0,>=1.32.0->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object_detection==0.1) (6.2.2)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.12/dist-packages (from markdown-it-py>=2.2.0->rich->keras->object_detection==0.1) (0.1.2)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn>=0.21.3->seqeval->tf-models-official>=2.5.1->object_detection==0.1) (1.5.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn>=0.21.3->seqeval->tf-models-official>=2.5.1->object_detection==0.1) (3.6.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.12/dist-packages (from tensorboard~=2.19.0->tensorflow~=2.19.0->tf-models-official>=2.5.1->object_detection==0.1) (3.10)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.12/dist-packages (from tensorboard~=2.19.0->tensorflow~=2.19.0->tf-models-official>=2.5.1->object_detection==0.1) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from tensorboard~=2.19.0->tensorflow~=2.19.0->tf-models-official>=2.5.1->object_detection==0.1) (3.1.3)\n",
            "Requirement already satisfied: docstring-parser<1.0,>=0.15 in /usr/local/lib/python3.12/dist-packages (from simple_parsing->tensorflow-datasets->tf-models-official>=2.5.1->object_detection==0.1) (0.17.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.12/dist-packages (from werkzeug>=1.0.1->tensorboard~=2.19.0->tensorflow~=2.19.0->tf-models-official>=2.5.1->object_detection==0.1) (3.0.3)\n",
            "Downloading pyparsing-2.4.7-py2.py3-none-any.whl (67 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.8/67.8 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading sacrebleu-2.2.0-py3-none-any.whl (116 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.6/116.6 kB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading apache_beam-2.69.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (17.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.2/17.2 MB\u001b[0m \u001b[31m82.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading contextlib2-21.6.0-py2.py3-none-any.whl (13 kB)\n",
            "Downloading lvis-0.5.3-py3-none-any.whl (14 kB)\n",
            "Downloading tensorflow_io-0.37.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (49.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.6/49.6 MB\u001b[0m \u001b[31m15.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tensorflow_io_gcs_filesystem-0.37.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.1/5.1 MB\u001b[0m \u001b[31m96.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading beartype-0.21.0-py3-none-any.whl (1.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m61.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading fastavro-1.12.1-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (3.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.5/3.5 MB\u001b[0m \u001b[31m92.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading fasteners-0.20-py3-none-any.whl (18 kB)\n",
            "Downloading grpcio-1.65.5-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.6/5.6 MB\u001b[0m \u001b[31m103.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading httplib2-0.22.0-py3-none-any.whl (96 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m96.9/96.9 kB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jsonpickle-3.4.2-py3-none-any.whl (46 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.3/46.3 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading objsize-0.7.1-py3-none-any.whl (11 kB)\n",
            "Downloading opencv_python-4.11.0.86-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (63.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.0/63.0 MB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pyarrow_hotfix-0.7-py3-none-any.whl (7.9 kB)\n",
            "Downloading pydot-1.4.2-py2.py3-none-any.whl (21 kB)\n",
            "Downloading pymongo-4.15.5-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (1.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m65.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading redis-5.3.1-py3-none-any.whl (272 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m272.8/272.8 kB\u001b[0m \u001b[31m19.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dnspython-2.8.0-py3-none-any.whl (331 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m331.1/331.1 kB\u001b[0m \u001b[31m22.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: object_detection, avro-python3, crcmod, hdfs, docopt\n",
            "  Building wheel for object_detection (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for object_detection: filename=object_detection-0.1-py3-none-any.whl size=1697325 sha256=008e33268943ecef9335fd8a7a80dea8c1e7e3e4913cdd1aa725328bcebee380\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-70j22th1/wheels/93/ad/c5/62cdd10f6d842d66f3d05020591434c5aefd0cdea6bcd6f0ff\n",
            "  Building wheel for avro-python3 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for avro-python3: filename=avro_python3-1.10.2-py3-none-any.whl size=43993 sha256=dfea55ed49d7448f3a1ff9fd466d9807d44e6171fd7ebdbb59d85e55f72bfb17\n",
            "  Stored in directory: /root/.cache/pip/wheels/df/82/f4/b7126d86d6a404dd59a822fad5f169000deee5f61f7c88580c\n",
            "  Building wheel for crcmod (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for crcmod: filename=crcmod-1.7-cp312-cp312-linux_x86_64.whl size=31832 sha256=b6fc8310a3e0035828d489a26e2fad8e49318a6206056e6447a6a5b3f3d0f13b\n",
            "  Stored in directory: /root/.cache/pip/wheels/76/08/0b/caa8b1380122cbfe6a03eaccbec0f63c67e619af4e30ca5e2a\n",
            "  Building wheel for hdfs (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for hdfs: filename=hdfs-2.7.3-py3-none-any.whl size=34324 sha256=7dd0b30715d4328120bb016a0cf4ab3f851b9a54163fb9ab006ec0b7599318ab\n",
            "  Stored in directory: /root/.cache/pip/wheels/97/ae/d9/536505928dd3a458b206013b02625df8f12d22fa154f2bfd65\n",
            "  Building wheel for docopt (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for docopt: filename=docopt-0.6.2-py2.py3-none-any.whl size=13706 sha256=5275d57daec88d912dfa17bf6fe2b1895b356f9cc1e4e561fa637ea675c9b66d\n",
            "  Stored in directory: /root/.cache/pip/wheels/1a/bf/a1/4cee4f7678c68c5875ca89eaccf460593539805c3906722228\n",
            "Successfully built object_detection avro-python3 crcmod hdfs docopt\n",
            "Installing collected packages: docopt, crcmod, tensorflow-io-gcs-filesystem, sacrebleu, redis, pyparsing, pyarrow-hotfix, opencv-python, objsize, jsonpickle, grpcio, fasteners, fastavro, dnspython, contextlib2, beartype, avro-python3, tensorflow_io, pymongo, pydot, httplib2, hdfs, lvis, apache-beam, object_detection\n",
            "  Attempting uninstall: sacrebleu\n",
            "    Found existing installation: sacrebleu 2.5.1\n",
            "    Uninstalling sacrebleu-2.5.1:\n",
            "      Successfully uninstalled sacrebleu-2.5.1\n",
            "  Attempting uninstall: pyparsing\n",
            "    Found existing installation: pyparsing 3.2.5\n",
            "    Uninstalling pyparsing-3.2.5:\n",
            "      Successfully uninstalled pyparsing-3.2.5\n",
            "  Attempting uninstall: opencv-python\n",
            "    Found existing installation: opencv-python 4.12.0.88\n",
            "    Uninstalling opencv-python-4.12.0.88:\n",
            "      Successfully uninstalled opencv-python-4.12.0.88\n",
            "  Attempting uninstall: jsonpickle\n",
            "    Found existing installation: jsonpickle 4.1.1\n",
            "    Uninstalling jsonpickle-4.1.1:\n",
            "      Successfully uninstalled jsonpickle-4.1.1\n",
            "  Attempting uninstall: grpcio\n",
            "    Found existing installation: grpcio 1.76.0\n",
            "    Uninstalling grpcio-1.76.0:\n",
            "      Successfully uninstalled grpcio-1.76.0\n",
            "  Attempting uninstall: beartype\n",
            "    Found existing installation: beartype 0.22.6\n",
            "    Uninstalling beartype-0.22.6:\n",
            "      Successfully uninstalled beartype-0.22.6\n",
            "  Attempting uninstall: pydot\n",
            "    Found existing installation: pydot 4.0.1\n",
            "    Uninstalling pydot-4.0.1:\n",
            "      Successfully uninstalled pydot-4.0.1\n",
            "  Attempting uninstall: httplib2\n",
            "    Found existing installation: httplib2 0.31.0\n",
            "    Uninstalling httplib2-0.31.0:\n",
            "      Successfully uninstalled httplib2-0.31.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "grpcio-status 1.71.2 requires grpcio>=1.71.2, but you have grpcio 1.65.5 which is incompatible.\n",
            "grpcio-status 1.71.2 requires protobuf<6.0dev,>=5.26.1, but you have protobuf 3.20.3 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed apache-beam-2.69.0 avro-python3-1.10.2 beartype-0.21.0 contextlib2-21.6.0 crcmod-1.7 dnspython-2.8.0 docopt-0.6.2 fastavro-1.12.1 fasteners-0.20 grpcio-1.65.5 hdfs-2.7.3 httplib2-0.22.0 jsonpickle-3.4.2 lvis-0.5.3 object_detection-0.1 objsize-0.7.1 opencv-python-4.11.0.86 pyarrow-hotfix-0.7 pydot-1.4.2 pymongo-4.15.5 pyparsing-2.4.7 redis-5.3.1 sacrebleu-2.2.0 tensorflow-io-gcs-filesystem-0.37.1 tensorflow_io-0.37.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pathlib\n",
        "import time\n",
        "import tensorflow as tf\n",
        "import imageio\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from object_detection.utils import \\\n",
        "  label_map_util, visualization_utils as viz_utils\n",
        "\n",
        "from PIL import Image\n",
        "%matplotlib inline\n"
      ],
      "metadata": {
        "id": "4XFgurdWkN6_"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
        "for gpu in gpus:\n",
        "    tf.config.experimental.set_memory_growth(gpu, True)"
      ],
      "metadata": {
        "id": "eY0XQOl3lJln"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Download Video**"
      ],
      "metadata": {
        "id": "ZaqFI1RiopzL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7KTVqiF7o5RF",
        "outputId": "2981d45d-1474-4cd1-96d4-d4a9cdcc8321"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget -nc https://lazyprogrammer.me/course_files/cnn_class2_videos.zip"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lSheqpfmotPY",
        "outputId": "a7c3236f-5bb3-42c1-afab-69507cf28b9c"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-12-07 07:09:05--  https://lazyprogrammer.me/course_files/cnn_class2_videos.zip\n",
            "Resolving lazyprogrammer.me (lazyprogrammer.me)... 172.67.213.166, 104.21.23.210, 2606:4700:3030::ac43:d5a6, ...\n",
            "Connecting to lazyprogrammer.me (lazyprogrammer.me)|172.67.213.166|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 2073140 (2.0M) [application/zip]\n",
            "Saving to: ‘cnn_class2_videos.zip’\n",
            "\n",
            "\rcnn_class2_videos.z   0%[                    ]       0  --.-KB/s               \rcnn_class2_videos.z 100%[===================>]   1.98M  --.-KB/s    in 0.05s   \n",
            "\n",
            "2025-12-07 07:09:05 (40.7 MB/s) - ‘cnn_class2_videos.zip’ saved [2073140/2073140]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip cnn_class2_videos.zip"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5ROwqE-vow5z",
        "outputId": "f0960fd4-605a-4c8e-9707-b570d92e7b91"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  cnn_class2_videos.zip\n",
            "  inflating: catdog.mp4              \n",
            "  inflating: safari.mp4              \n",
            "  inflating: traffic.mp4             \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NdYPj3Kgo1rZ",
        "outputId": "e2585b46-727f-4818-b04a-8753e8b10e8f"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "catdog.mp4  cnn_class2_videos.zip  models  safari.mp4  sample_data  traffic.mp4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "INPUT_VIDEO = ['catdog.mp4', 'safari.mp4', 'traffic.mp4']"
      ],
      "metadata": {
        "id": "M0LG-ixYpTsp"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Download and extract model files**"
      ],
      "metadata": {
        "id": "DzFnMzOzhqC-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Get URLs from the \"Object Detection Zoo\": https://github.com/tensorflow/models/blob/master/research/object_detection/g3doc/tf2_detection_zoo.md"
      ],
      "metadata": {
        "id": "SRqg3IfZhrbD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "url= 'http://download.tensorflow.org/models/object_detection/tf2/20200711/efficientdet_d2_coco17_tpu-32.tar.gz'"
      ],
      "metadata": {
        "id": "lblCpETFpi9K"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "PATH_TO_MODEL_DIR = tf.keras.utils.get_file(\n",
        "    fname= 'efficientdet_d2_coco17_tpu-32',\n",
        "    origin=url,\n",
        "    untar=True\n",
        ")\n",
        "PATH_TO_MODEL_DIR"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "y7-CQ23Cpjuz",
        "outputId": "29c8cc34-41c6-4205-9438-4288e2d5e94e"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/root/.keras/datasets/efficientdet_d2_coco17_tpu-32'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "da590768",
        "outputId": "b426cd04-997f-4834-c513-4dca9d6a3485"
      },
      "source": [
        "!ls -F {PATH_TO_MODEL_DIR}"
      ],
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ssd_resnet101_v1_fpn_640x640_coco17_tpu-8/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Download Labels File**\n",
        "\n",
        "Label files can be found here: https://github.com/tensorflow/models/tree/master/research/object_detection/data\n",
        "\n",
        "You probably won't need these since Object Detection Zoo contains only models trained on COCO.\n",
        "\n"
      ],
      "metadata": {
        "id": "9vWQffRdhxxh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "url1 = 'https://raw.githubusercontent.com/tensorflow/models/master/research/object_detection/data/mscoco_label_map.pbtxt'"
      ],
      "metadata": {
        "id": "n6GWUHITpuVt"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!rm {PATH_TO_LABELS}\n",
        "!wget -O {PATH_TO_LABELS} {url1}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EcdqgENkpwQr",
        "outputId": "1270d57a-93e8-498d-abcb-ff5aaa34f591"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-12-07 07:25:11--  https://raw.githubusercontent.com/tensorflow/models/master/research/object_detection/data/mscoco_label_map.pbtxt\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.111.133, 185.199.110.133, 185.199.109.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.111.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 5056 (4.9K) [text/plain]\n",
            "Saving to: ‘/root/.keras/datasets/mscoco_label_map.pbtxt’\n",
            "\n",
            "\r          /root/.ke   0%[                    ]       0  --.-KB/s               \r/root/.keras/datase 100%[===================>]   4.94K  --.-KB/s    in 0s      \n",
            "\n",
            "2025-12-07 07:25:11 (54.8 MB/s) - ‘/root/.keras/datasets/mscoco_label_map.pbtxt’ saved [5056/5056]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "PATH_TO_LABELS"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "3-kyYpA0qfXd",
        "outputId": "ef0eadea-eb74-42a3-d01f-678272b1a3f2"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/root/.keras/datasets/mscoco_label_map.pbtxt'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!head {PATH_TO_LABEL}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_fWu3hktp1KK",
        "outputId": "ed3c013d-4d39-43ad-af14-b36835b8e688"
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "item {\n",
            "  name: \"/m/01g317\"\n",
            "  id: 1\n",
            "  display_name: \"person\"\n",
            "}\n",
            "item {\n",
            "  name: \"/m/0199g\"\n",
            "  id: 2\n",
            "  display_name: \"bicycle\"\n",
            "}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4055003d"
      },
      "source": [
        "#### **Load in the Label Map**"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "🧠 What’s happening when you run the detector\n",
        "\n",
        "* Your downloaded model (e.g. ssd_resnet101_v1_fpn_640x640_coco17_tpu-8)\n",
        "was trained on COCO dataset.\n",
        "\n",
        "* During inference, the model outputs things like:\n",
        "\n",
        "\n",
        "```\n",
        "detections['detection_boxes']      # bounding boxes\n",
        "detections['detection_classes']    # class IDs (1, 2, 3, ...)\n",
        "detections['detection_scores']     # confidence scores\n",
        "\n",
        "```\n",
        "\n"
      ],
      "metadata": {
        "id": "lzny49SZhxHG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Load in the model**"
      ],
      "metadata": {
        "id": "v0tlbXpBiE29"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "PATH_TO_SAVED_MODEL = os.path.join(PATH_TO_MODEL_DIR, 'ssd_resnet101_v1_fpn_640x640_coco17_tpu-8', 'saved_model')"
      ],
      "metadata": {
        "id": "NhdpXsAyqEGr"
      },
      "execution_count": 74,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!ls {PATH_TO_SAVED_MODEL}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8nOIpjkNqmft",
        "outputId": "03cda030-107d-43f1-9198-c0056fab41cc"
      },
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "assets\tsaved_model.pb\tvariables\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print('Loading model...', end='')\n",
        "start_time = time.time()\n",
        "\n",
        "# Load saved model and build the detection function\n",
        "detect_fn = tf.saved_model.load(PATH_TO_SAVED_MODEL)\n",
        "\n",
        "end_time = time.time()\n",
        "elapsed_time = end_time - start_time\n",
        "print('Done! Took {} seconds'.format(elapsed_time))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YcDviX1Hq3Is",
        "outputId": "715a5a9d-b858-4a1a-eaf1-7a6eddae4a25"
      },
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading model...Done! Took 83.99462151527405 seconds\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Load in the Label**"
      ],
      "metadata": {
        "id": "P0cyChmliF93"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "category_index = label_map_util.create_category_index_from_labelmap(\n",
        "    PATH_TO_LABELS,\n",
        "    use_display_name=True\n",
        ")"
      ],
      "metadata": {
        "id": "7Hehmf7Yvqz-"
      },
      "execution_count": 77,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "category_index"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jQxwFaFNvx-1",
        "outputId": "af9075ef-e0f8-460e-840a-8fb8668aabd3"
      },
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{1: {'id': 1, 'name': 'person'},\n",
              " 2: {'id': 2, 'name': 'bicycle'},\n",
              " 3: {'id': 3, 'name': 'car'},\n",
              " 4: {'id': 4, 'name': 'motorcycle'},\n",
              " 5: {'id': 5, 'name': 'airplane'},\n",
              " 6: {'id': 6, 'name': 'bus'},\n",
              " 7: {'id': 7, 'name': 'train'},\n",
              " 8: {'id': 8, 'name': 'truck'},\n",
              " 9: {'id': 9, 'name': 'boat'},\n",
              " 10: {'id': 10, 'name': 'traffic light'},\n",
              " 11: {'id': 11, 'name': 'fire hydrant'},\n",
              " 13: {'id': 13, 'name': 'stop sign'},\n",
              " 14: {'id': 14, 'name': 'parking meter'},\n",
              " 15: {'id': 15, 'name': 'bench'},\n",
              " 16: {'id': 16, 'name': 'bird'},\n",
              " 17: {'id': 17, 'name': 'cat'},\n",
              " 18: {'id': 18, 'name': 'dog'},\n",
              " 19: {'id': 19, 'name': 'horse'},\n",
              " 20: {'id': 20, 'name': 'sheep'},\n",
              " 21: {'id': 21, 'name': 'cow'},\n",
              " 22: {'id': 22, 'name': 'elephant'},\n",
              " 23: {'id': 23, 'name': 'bear'},\n",
              " 24: {'id': 24, 'name': 'zebra'},\n",
              " 25: {'id': 25, 'name': 'giraffe'},\n",
              " 27: {'id': 27, 'name': 'backpack'},\n",
              " 28: {'id': 28, 'name': 'umbrella'},\n",
              " 31: {'id': 31, 'name': 'handbag'},\n",
              " 32: {'id': 32, 'name': 'tie'},\n",
              " 33: {'id': 33, 'name': 'suitcase'},\n",
              " 34: {'id': 34, 'name': 'frisbee'},\n",
              " 35: {'id': 35, 'name': 'skis'},\n",
              " 36: {'id': 36, 'name': 'snowboard'},\n",
              " 37: {'id': 37, 'name': 'sports ball'},\n",
              " 38: {'id': 38, 'name': 'kite'},\n",
              " 39: {'id': 39, 'name': 'baseball bat'},\n",
              " 40: {'id': 40, 'name': 'baseball glove'},\n",
              " 41: {'id': 41, 'name': 'skateboard'},\n",
              " 42: {'id': 42, 'name': 'surfboard'},\n",
              " 43: {'id': 43, 'name': 'tennis racket'},\n",
              " 44: {'id': 44, 'name': 'bottle'},\n",
              " 46: {'id': 46, 'name': 'wine glass'},\n",
              " 47: {'id': 47, 'name': 'cup'},\n",
              " 48: {'id': 48, 'name': 'fork'},\n",
              " 49: {'id': 49, 'name': 'knife'},\n",
              " 50: {'id': 50, 'name': 'spoon'},\n",
              " 51: {'id': 51, 'name': 'bowl'},\n",
              " 52: {'id': 52, 'name': 'banana'},\n",
              " 53: {'id': 53, 'name': 'apple'},\n",
              " 54: {'id': 54, 'name': 'sandwich'},\n",
              " 55: {'id': 55, 'name': 'orange'},\n",
              " 56: {'id': 56, 'name': 'broccoli'},\n",
              " 57: {'id': 57, 'name': 'carrot'},\n",
              " 58: {'id': 58, 'name': 'hot dog'},\n",
              " 59: {'id': 59, 'name': 'pizza'},\n",
              " 60: {'id': 60, 'name': 'donut'},\n",
              " 61: {'id': 61, 'name': 'cake'},\n",
              " 62: {'id': 62, 'name': 'chair'},\n",
              " 63: {'id': 63, 'name': 'couch'},\n",
              " 64: {'id': 64, 'name': 'potted plant'},\n",
              " 65: {'id': 65, 'name': 'bed'},\n",
              " 67: {'id': 67, 'name': 'dining table'},\n",
              " 70: {'id': 70, 'name': 'toilet'},\n",
              " 72: {'id': 72, 'name': 'tv'},\n",
              " 73: {'id': 73, 'name': 'laptop'},\n",
              " 74: {'id': 74, 'name': 'mouse'},\n",
              " 75: {'id': 75, 'name': 'remote'},\n",
              " 76: {'id': 76, 'name': 'keyboard'},\n",
              " 77: {'id': 77, 'name': 'cell phone'},\n",
              " 78: {'id': 78, 'name': 'microwave'},\n",
              " 79: {'id': 79, 'name': 'oven'},\n",
              " 80: {'id': 80, 'name': 'toaster'},\n",
              " 81: {'id': 81, 'name': 'sink'},\n",
              " 82: {'id': 82, 'name': 'refrigerator'},\n",
              " 84: {'id': 84, 'name': 'book'},\n",
              " 85: {'id': 85, 'name': 'clock'},\n",
              " 86: {'id': 86, 'name': 'vase'},\n",
              " 87: {'id': 87, 'name': 'scissors'},\n",
              " 88: {'id': 88, 'name': 'teddy bear'},\n",
              " 89: {'id': 89, 'name': 'hair drier'},\n",
              " 90: {'id': 90, 'name': 'toothbrush'}}"
            ]
          },
          "metadata": {},
          "execution_count": 78
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Object Detection**"
      ],
      "metadata": {
        "id": "oP4yWxj4idoi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "To make the code snippet you provided suitable for a text cell in a Colab notebook, you should convert the Python function into a clear explanation of its steps, dependencies, and purpose.\n",
        "\n",
        "Here is a structured explanation you can use in a Colab text cell:\n",
        "\n",
        "-----\n",
        "\n",
        "# 🤖 Object Detection Function Explained\n",
        "\n",
        "This text cell provides a detailed explanation of the Python function `detectObject(image_np)`, which is typically used in a Jupyter or Colab environment for real-time or batch object detection using a pre-trained TensorFlow model.\n",
        "\n",
        "The function takes a NumPy image array, runs it through a detection model, and draws the resulting bounding boxes and labels onto the image.\n",
        "\n",
        "## 📦 Prerequisites (Assumed Imports)\n",
        "\n",
        "The function relies on several external libraries and variables that must be defined and imported in the code cells:\n",
        "\n",
        "  * `tf`: **TensorFlow** (for Tensor operations and the model).\n",
        "  * `np`: **NumPy** (for array manipulation).\n",
        "  * `detect_fn`: The **loaded TensorFlow detection model** (a function that takes an image tensor and returns detection results).\n",
        "  * `viz_utils`: The **visualization utilities** (often from `object_detection.utils.visualization_utils`).\n",
        "  * `category_index`: A **dictionary** mapping numerical class IDs to human-readable labels (e.g., `{1: {'id': 1, 'name': 'person'}}`).\n",
        "\n",
        "-----\n",
        "\n",
        "## 🔬 Function Breakdown: `detectObject(image_np)`\n",
        "\n",
        "| Step | Code | Purpose |\n",
        "| :--- | :--- | :--- |\n",
        "| **1. Preprocessing (Input)** | `input_tensor = tf.convert_to_tensor(image_np)`<br>`input_tensor = input_tensor[tf.newaxis, ...]` | Converts the input **NumPy array** (`image_np`) into a **TensorFlow Tensor**. A new axis (`tf.newaxis`) is added to the front to create the **batch dimension** (required input shape: `[1, H, W, C]`). |\n",
        "| **2. Inference** | `detections = detect_fn(input_tensor)` | Passes the prepared tensor to the pre-loaded model (`detect_fn`) to perform object detection. The model returns a dictionary of raw detection outputs (boxes, classes, scores). |\n",
        "| **3. Postprocessing (Output)** | `num_detections = int(detections.pop('num_detections'))`<br>`detections = {...}`<br>`detections['detection_classes'] = ...astype(np.int64)` | Extracts the actual number of detections and converts the raw detection Tensors (which include the batch dimension) into **NumPy arrays** containing only the valid results. Ensures class IDs are integers. |\n",
        "| **4. Visualization** | `image_np_with_detections = image_np.copy()`<br>`viz_utils.visualize_boxes_and_labels_on_image_array(...)` | Creates a copy of the original image. The `visualize_boxes_and_labels_on_image_array` function draws **bounding boxes**, **scores**, and **labels** onto this image copy based on the processed detection data.<br>*Note: Only detections with a `min_score_thresh` of **0.30** or higher are drawn.* |\n",
        "| **5. Return Value** | `return image_np_with_detections` | Returns the modified image (as a NumPy array) with the detection results overlaid. |\n",
        "\n",
        "-----\n",
        "\n",
        "## 🛠️ Typical Use Case\n",
        "\n",
        "This function is commonly placed inside a loop to process video streams or multiple images, creating a pipeline for real-time object detection applications."
      ],
      "metadata": {
        "id": "gKDHWrlbx63o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def detectObject(image_np):\n",
        "  # Numpy ----> Tensor\n",
        "  input_tensor = tf.convert_to_tensor(image_np)\n",
        "  # New Axis\n",
        "  input_tensor = input_tensor[tf.newaxis, ...]\n",
        "\n",
        "  detections = detect_fn(input_tensor)\n",
        "\n",
        "  num_detections = int(detections.pop('num_detections'))\n",
        "  detections = {key: value[0, :num_detections].numpy()\n",
        "                   for key, value in detections.items()}\n",
        "  detections['num_detections'] = num_detections\n",
        "\n",
        "  # detection_classes should be ints.\n",
        "  detections['detection_classes'] = detections['detection_classes'].astype(np.int64)\n",
        "\n",
        "  image_np_with_detections = image_np.copy()\n",
        "\n",
        "  viz_utils.visualize_boxes_and_labels_on_image_array(\n",
        "        image_np_with_detections,\n",
        "        detections['detection_boxes'],\n",
        "        detections['detection_classes'],\n",
        "        detections['detection_scores'],\n",
        "        category_index,\n",
        "        use_normalized_coordinates=True,\n",
        "        max_boxes_to_draw=200,\n",
        "        min_score_thresh=.30,\n",
        "        agnostic_mode=False)\n",
        "\n",
        "  return image_np_with_detections"
      ],
      "metadata": {
        "id": "FLnYLV1bhX8p"
      },
      "execution_count": 79,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def object_in_video(input_video):\n",
        "  print(f'Running for {input_video} ...', end='')\n",
        "  video_reader = imageio.get_reader(f'{input_video}')\n",
        "  video_writer = imageio.get_writer(f'{input_video.replace(\".mp4\", \"\")}_annotated.mp4', fps=10)\n",
        "\n",
        "  # loop through and process each frame\n",
        "  t0 = time.time()\n",
        "  n_frames = 0\n",
        "  for frame in video_reader:\n",
        "      n_frames += 1\n",
        "      new_frame = detectObject(frame)\n",
        "\n",
        "      # instead of plotting image, we write the frame to video\n",
        "      video_writer.append_data(new_frame)\n",
        "\n",
        "  fps = n_frames / (time.time() - t0)\n",
        "  print(\"Frames processed: %s, Speed: %s fps\" % (n_frames, fps))\n",
        "\n",
        "  # clean up\n",
        "  video_writer.close()"
      ],
      "metadata": {
        "id": "perd6kzxx757"
      },
      "execution_count": 84,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "object_in_video(INPUT_VIDEO[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eVX6VGh9zswP",
        "outputId": "5ec0c15b-bbbb-4ab6-8a57-aa9d5e0a1fad"
      },
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running for catdog.mp4 ...Frames processed: 50, Speed: 0.15847605514254753 fps\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "object_in_video(INPUT_VIDEO[1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Efiraw84zvC7",
        "outputId": "6211a1cd-c3d3-426b-ace2-041ea9619497"
      },
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running for safari.mp4 ..."
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:imageio_ffmpeg:IMAGEIO FFMPEG_WRITER WARNING: input image is not divisible by macro_block_size=16, resizing from (640, 360) to (640, 368) to ensure video compatibility with most codecs and players. To prevent resizing, make your input image divisible by the macro_block_size or set the macro_block_size to 1 (risking incompatibility).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Frames processed: 100, Speed: 0.16740313619177258 fps\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "object_in_video(INPUT_VIDEO[2])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lc21NyjJ0L_P",
        "outputId": "dff09da8-9c32-4e34-990a-778bb56cd0d3"
      },
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running for traffic.mp4 ...Frames processed: 70, Speed: 0.1674075409231666 fps\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uW3KIQGC7Vg7",
        "outputId": "b6991ea9-0bdf-4970-d4aa-7f367bc2a4de"
      },
      "execution_count": 90,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!cp \"/content/catdog_annotated.mp4\"  \"/content/drive/MyDrive/\"\n"
      ],
      "metadata": {
        "id": "Ifx9H5KB7XYF"
      },
      "execution_count": 91,
      "outputs": []
    }
  ]
}